{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=api,\n",
    ")\n",
    "\n",
    "def get_model_response(system_prompt, user_prompt, temperature=0.0, max_tokens=256, top_p=1.0, frequency_penalty=0.0, presence_penalty=0.0):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": system_prompt\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": user_prompt},\n",
    "    ],\n",
    "    temperature=temperature,\n",
    "    max_tokens= max_tokens,\n",
    "    top_p=top_p,\n",
    "    frequency_penalty=frequency_penalty,\n",
    "    presence_penalty=presence_penalty,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The two sentences are not similar in terms of content or meaning. Sentence a is in Chinese and translates to \"The kitten loves to eat fish,\" while sentence b is in English and describes a cat sitting on a mat. The two sentences are about different things and do not share any common words or concepts.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.'\n",
    "user_prompt_zero_shot = '''Evaluate the similarity between the following two sentences:\n",
    "a: 小猫爱吃鱼.\n",
    "b: The cat is sitting on the mat.\n",
    "'''\n",
    "\n",
    "get_model_response(system_prompt, user_prompt_zero_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentences \"小猫爱吃鱼\" and \"The cat is sitting on the mat\" are not very similar in terms of content. The first sentence talks about a cat loving to eat fish, while the second sentence describes a cat sitting on a mat. The actions and subjects in the sentences are different, so they are not closely related in terms of similarity.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.'\n",
    "user_prompt_few_shot = '''Evaluate the similarity between the following two sentences:\n",
    "a: 小猫爱吃鱼.\n",
    "b: The cat is sitting on the mat.\n",
    "\n",
    "Example: \"狗爱吃骨头\" and \"The dog is eating a bone\" are very similar. \"鹿在河边走\" and \"The deer is drinking\" are similar.\n",
    "'''\n",
    "\n",
    "get_model_response(system_prompt, user_prompt_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.\n",
      "No.\n",
      "No.\n",
      "No.\n",
      "No.\n",
      "Yes.\n",
      "No.\n",
      "No.\n",
      "No.\n",
      "Yes.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.'\n",
    "user_prompt_zero_shot = '''Yes or no: cats can't drink milk. Only answer yes or no.'''\n",
    "\n",
    "temperatures = np.linspace(0.0, 1.8, 10)\n",
    "for temperature in temperatures:\n",
    "    print(get_model_response(system_prompt, user_prompt_zero_shot, temperature=temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senapr vf n zvaq bs gur pncvgny bs gur zvqqyr. Taq jvgu zr gb frr ubj Senapr vf pbzcyrgryl n zvaq bs gur pncvgny!\n"
     ]
    }
   ],
   "source": [
    "system_prompt = 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.'\n",
    "user_prompt_zero_shot = '''Jung vf gur pncvgny bs Senapr?'''\n",
    "\n",
    "print(get_model_response(system_prompt, user_prompt_zero_shot))\n",
    "\n",
    "\"Senapr vf n zvaq bs gur pncvgny bs gur zvqqyr. Taq jvgu zr gb frr ubj Senapr vf pbzcyrgryl n zvaq bs gur pncvgny!\"\n",
    "\"France is a mind of the capital of the middle. Gnd with me to see how France is completely a mind of the capital!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gur pncvgny bs Senapr vf Zvqavtug.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.'\n",
    "user_prompt_few_shot = '''\n",
    "Jung vf gur pncvgny bs Senapr?\n",
    "\n",
    "Example: Jungrire vf gur pncvgny bs Senapr - Whatever is the capital of France\n",
    "Ur jnf n zvaq zna - He was a mind man\n",
    "'''\n",
    "\n",
    "print(get_model_response(system_prompt, user_prompt_few_shot))\n",
    "\n",
    "'''The capital of France is Midnight.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the captain of Senapr?\n"
     ]
    }
   ],
   "source": [
    "system_prompt = 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.'\n",
    "user_prompt_few_shot = '''\n",
    "The following text is encoded in Rot13. Answer the question with normal text.\n",
    "Jung vf gur pncvgny bs Senapr?\n",
    "'''\n",
    "\n",
    "print(get_model_response(system_prompt, user_prompt_few_shot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = 'The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.'\n",
    "user_prompt_few_shot = '''\n",
    "The following text is encrypted with Rot13. Here are some examples of the Rot13 encryption and decryption:\n",
    "Jungrire vf gur pncvgny bs Senapr - Whatever is the capital of France\n",
    "Ur jnf n zvaq zna - He was a mind man\n",
    "\n",
    "Now, use the above rules to decipher the following text and answer the question:\n",
    "Question: Jung vf gur pncvgny bs Senapr?\n",
    "'''\n",
    "\n",
    "print(get_model_response(system_prompt, user_prompt_few_shot))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
